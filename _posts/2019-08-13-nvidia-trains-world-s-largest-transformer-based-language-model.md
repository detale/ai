---
category: news
title: "Nvidia trains world’s largest Transformer-based language model"
abstract: "Nvidia was able to train BERT-Large using optimized PyTorch software and a DGX-SuperPOD of more than 1,000 GPUs that is able to train BERT in 53 minutes. “Without this kind of technology ..."
publishedDateTime: 2019-08-13T14:00:00Z
sourceUrl: https://venturebeat.com/2019/08/13/nvidia-trains-worlds-largest-transformer-based-language-model/
ampUrl: https://venturebeat.com/2019/08/13/nvidia-trains-worlds-largest-transformer-based-language-model/amp/
cdnAmpUrl: https://venturebeat-com.cdn.ampproject.org/c/s/venturebeat.com/2019/08/13/nvidia-trains-worlds-largest-transformer-based-language-model/amp/
type: article
quality: 54
score: 54
published: true

provider:
  name: VentureBeat
  id: venturebeat.com

topics:
  - AI
  - Facebook AI
---
