---
category: news
title: "NVIDIA registers the world's quickest BERT training time and largest transformer-based model"
abstract: "This record was set using 1,472 V100 SXM3-32GB GPUs and 10 Mellanox Infiniband adapters per node, running PyTorch with Automatic Mixed Precision to accelerate throughput. Another category of transformer-based NLP networks is used for generative language ..."
publishedDateTime: 2019-08-13T21:32:00Z
sourceUrl: https://www.neowin.net/news/nvidia-registers-the-worlds-quickest-bert-training-time-and-largest-transformer-based-model
ampUrl: https://www.neowin.net/amp/nvidia-registers-the-worlds-quickest-bert-training-time-and-largest-transformer-based-model/
cdnAmpUrl: https://www-neowin-net.cdn.ampproject.org/c/s/www.neowin.net/amp/nvidia-registers-the-worlds-quickest-bert-training-time-and-largest-transformer-based-model/
type: article
quality: 39
score: 39
published: false

provider:
  name: Neowin
  id: neowin.net

topics:
  - AI
  - Facebook AI

images:
  - url: https://cdn.neow.in/news/images/uploaded/2018/05/1525896938_nvidialogo4_story.jpg
    width: 760
    height: 428
    title: "NVIDIA registers the world's quickest BERT training time and largest transformer-based model"
---
