---
category: news
title: "Google Releases Post-Training Integer Quantization for TensorFlow Lite"
abstract: "Google announced new tooling for their TensorFlow Lite deep-learning framework that reduces the size of models and latency of inference. The tool converts a trained model's weights from floating-point representation to 8-bit signed integers. This reduces ..."
publishedDateTime: 2019-07-23T13:29:00Z
sourceUrl: https://www.infoq.com/news/2019/07/tensorflow-lite-quantization/
type: article
quality: 24
score: 24
published: false

provider:
  name: InfoQ
  id: infoq.com

topics:
  - AI
  - Google AI

images:
  - url: https://res.infoq.com/news/2019/07/tensorflow-lite-quantization/en/headerimage/tensorflow-lite-quantization-1563891656969.jpg
    width: 1200
    height: 800
    title: "Google Releases Post-Training Integer Quantization for TensorFlow Lite"
---
